{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "#%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, LassoCV,LassoLarsCV, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import skew\n",
    "from readData import readData\n",
    "\n",
    "def RMSLE_(y_val, y_val_pred):\n",
    "    return np.sqrt(np.mean((np.log(y_val+1)-np.log(y_val_pred+1))**2))\n",
    "RMSLE = make_scorer(RMSLE_, greater_is_better=False) \n",
    "\n",
    "def RMSE_(y_val, y_val_pred):\n",
    "    return np.sqrt(np.mean((y_val-y_val_pred)**2))\n",
    "RMSE = make_scorer(RMSE_, greater_is_better=False)\n",
    "\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_submission(prediction,score,comment):\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = '../result/submission_'+str(score)+'_'+str(now.strftime(\"%Y-%m-%d-%H-%M\"))+comment+'.csv'\n",
    "    #sub_file = 'prediction_training.csv'\n",
    "    print ('Creating submission: ', sub_file)\n",
    "    pd.DataFrame({'id': pd.read_csv('../../input/test.csv').id, 'price_doc': prediction}).to_csv(sub_file, index=False)\n",
    "\n",
    "# train need to be test when do test prediction\n",
    "def data_preprocess(X_train,X_test):\n",
    "#     outlier_idx = [4,11,13,20,46,66,70,167,178,185,199, 224,261, 309,313,318, 349,412,423,440,454,477,478, 523,540, 581,588,595,654,688, 691, 774, 798, 875, 898,926,970,987,1027,1109, 1169,1182,1239, 1256,1298,1324,1353,1359,1405,1442,1447]\n",
    "#     train.drop(train.index[outlier_idx],inplace=True)\n",
    "    all_data = pd.concat((X_train,X_test))\n",
    "    \n",
    "#     lowerClipCol = ['floor_from_top', 'roomsize', 'extra_area', 'age_at_sale']\n",
    "#     for c in lowerClipCol:\n",
    "#         all_data[[c]]=all_data[[c]].clip(lower=0)\n",
    "    \n",
    "# # #     to_delete = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n",
    "# # #     all_data = all_data.drop(to_delete,axis=1)\n",
    "\n",
    "# #     #train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "# #     #log transform skewed numeric features\n",
    "#     numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "#     skewed_feats = X_train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "#     skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "#     skewed_feats = skewed_feats.index\n",
    "#     all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
    "#     #all_data = pd.get_dummies(all_data)\n",
    "    #all_data = all_data.fillna(all_data.median())\n",
    "    \n",
    "    all_data.replace([np.infty, -np.infty], np.nan)\n",
    "    imp = Imputer(missing_values=np.nan, strategy='median')\n",
    "    all_data=pd.DataFrame(imp.fit_transform(all_data), columns=all_data.columns)\n",
    "    imp = Imputer(missing_values=np.infty, strategy='median')\n",
    "    all_data=pd.DataFrame(imp.fit_transform(all_data), columns=all_data.columns)\n",
    "\n",
    "    X_train = all_data[:X_train.shape[0]]\n",
    "    X_test = all_data[X_train.shape[0]:]\n",
    "    \n",
    "#     imp = Imputer(missing_values=np.nan, strategy='median')\n",
    "#     imp.fit(all_data)\n",
    "#     X_train = pd.DataFrame(imp.transform(X_train),columns=X_train.columns)\n",
    "#     X_test = pd.DataFrame(imp.transform(X_test),columns=X_test.columns)\n",
    "    \n",
    "#     imp = Imputer(missing_values=np.infty, strategy='median')\n",
    "#     imp.fit(pd.concat([X_train,X_test]))\n",
    "#     X_train = pd.DataFrame(imp.transform(X_train),columns=X_train.columns)\n",
    "#     X_test = pd.DataFrame(imp.transform(X_test),columns=X_test.columns)\n",
    "\n",
    "    return X_train,X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class ensemble(object):\n",
    "    def __init__(self, n_folds, stacker, base_models):\n",
    "        self.n_folds = n_folds\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "    def fit_predict(self,train,test,ytr):\n",
    "        X = train.values\n",
    "        y = ytr.values\n",
    "        T = test.values\n",
    "        folds = list(KFold(len(y), n_folds = self.n_folds, shuffle = True, random_state = 0))\n",
    "        S_train = np.zeros((X.shape[0],len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0],len(self.base_models))) \n",
    "        for i,reg in enumerate(base_models):\n",
    "            print (\"Fitting the base model...\")\n",
    "            S_test_i = np.zeros((T.shape[0],len(folds))) \n",
    "            for j, (train_idx,test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                reg.fit(X_train,y_train)\n",
    "                y_pred = reg.predict(X_holdout)[:]\n",
    "                S_train[test_idx,i] = y_pred\n",
    "                S_test_i[:,j] = reg.predict(T)[:]\n",
    "            S_test[:,i] = S_test_i.mean(1)\n",
    "         \n",
    "        print (\"Stacking base models...\")\n",
    "        # tuning the stacker\n",
    "        param_grid = {\n",
    "            'alpha': [1e-3,5e-3,1e-2,5e-2,1e-1,0.2,0.3,0.4,0.5,0.8,1e0,3,5,7,1e1],\n",
    "        }\n",
    "        grid = GridSearchCV(estimator=self.stacker, param_grid=param_grid, n_jobs=1, cv=5, scoring=RMSE)\n",
    "        grid.fit(S_train, y)\n",
    "        try:\n",
    "            print('Param grid:')\n",
    "            print(param_grid)\n",
    "            print('Best Params:')\n",
    "            print(grid.best_params_)\n",
    "            print('Best CV Score:')\n",
    "            print(-grid.best_score_)\n",
    "            print('Best estimator:')\n",
    "            print(grid.best_estimator_)\n",
    "            print(message)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        y_pred = grid.predict(S_test)[:]\n",
    "        return y_pred, -grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conbined_data: (36650, 702)\n"
     ]
    }
   ],
   "source": [
    "train, test, y_train = readData()\n",
    "\n",
    "# build a model library (can be improved)\n",
    "base_models = [\n",
    "        RandomForestRegressor(max_depth=6, n_jobs=-1, random_state=123,\n",
    "            n_estimators=500, max_features=.95\n",
    "        ), #0.34513\n",
    "        RandomForestRegressor(max_depth=5, n_jobs=-1, random_state=123,\n",
    "            n_estimators=500, max_features=.95\n",
    "        ), #0.34513\n",
    "        ExtraTreesRegressor(\n",
    "            n_jobs=-1, random_state=0, \n",
    "            n_estimators=500, max_features=15\n",
    "        ),\n",
    "        ExtraTreesRegressor(\n",
    "            n_jobs=-1, random_state=0, \n",
    "          n_estimators=500, max_features=20\n",
    "        ),\n",
    "        GradientBoostingRegressor(learning_rate=0.02, n_estimators=500, min_samples_leaf=70, \n",
    "            min_samples_split=200, max_features='sqrt',max_depth=6,subsample=0.85,random_state=10\n",
    "            ), #LB 0.32465\n",
    "        GradientBoostingRegressor(\n",
    "            random_state=0, \n",
    "            n_estimators=500, max_features=15, max_depth=6,\n",
    "            learning_rate=0.05, subsample=0.8\n",
    "        ),\n",
    "        XGBRegressor(seed=5, learning_rate=.02, subsample=.95, max_depth=6, min_child_weight=3, \n",
    "            n_estimators=500, colsample_bytree=0.95\n",
    "        ), #0.31625 \n",
    "        XGBRegressor(seed=5, learning_rate=.05, subsample=.7, max_depth=5, #min_child_weight=3, \n",
    "            #n_estimators=250, \n",
    "            colsample_bytree=0.7\n",
    "        ), #0.31625\n",
    "        LassoCV(alphas = [1, 0.1, 0.001, 0.0005]),\n",
    "        KNeighborsRegressor(n_neighbors = 5),\n",
    "        KNeighborsRegressor(n_neighbors = 10),\n",
    "        KNeighborsRegressor(n_neighbors = 15),\n",
    "        KNeighborsRegressor(n_neighbors = 25),\n",
    "        LassoLarsCV(),\n",
    "        ElasticNet(),\n",
    "        SVR()\n",
    "    ]\n",
    "\n",
    "ensem = ensemble(\n",
    "        n_folds=5,\n",
    "        stacker=Ridge(),\n",
    "        base_models=base_models\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the base model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4bd5f7c1fa39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#np.log1p(y_train))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcreate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"skewAdded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-76bedbbc956b>\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, train, test, ytr)\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mX_holdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_holdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mS_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train,X_test= data_preprocess(train,test)\n",
    "y_pred, score = ensem.fit_predict(X_train,X_test,y_train)#np.log1p(y_train))\n",
    "\n",
    "create_submission(np.expm1(y_pred),score,\"skewAdded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
