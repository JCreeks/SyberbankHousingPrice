{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用基本的特征构建基本的 xgboost 模型\n",
    "@author: MarkLiu\n",
    "@time  : 17-5-25 下午9:03\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "# remove warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# my own module\n",
    "from features import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CV(isLog1p=True):\n",
    "    train, test, macro = data_utils.load_data()\n",
    "\n",
    "    mult = .969\n",
    "\n",
    "    train['price_doc'] = train[\"price_doc\"] * mult + 10\n",
    "    if (isLog1p):\n",
    "        train['price_doc'] = np.log1p(train['price_doc'])\n",
    "    ylog_train_all = train['price_doc']\n",
    "    id_train = train['id']\n",
    "    train.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "    #submit_ids = test['id']\n",
    "    submit_ids = pd.read_csv('../../input/test.csv')['id']\n",
    "    test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "    # 合并训练集和测试集\n",
    "    conbined_data = pd.concat([train[test.columns.values], test])\n",
    "    # macro_cols = [\"balance_trade\", \"balance_trade_growth\", \"eurrub\", \"average_provision_of_build_contract\",\n",
    "    #               \"micex_rgbi_tr\", \"micex_cbi_tr\", \"deposits_rate\", \"mortgage_value\", \"mortgage_rate\",\n",
    "    #               \"income_per_cap\", \"rent_price_4+room_bus\", \"museum_visitis_per_100_cap\", \"apartment_build\", \"timestamp\"]\n",
    "    # conbined_data = pd.merge_ordered(conbined_data, macro[macro_cols], on='timestamp', how='left')\n",
    "\n",
    "    conbined_data.drop(['timestamp'], axis=1, inplace=True)\n",
    "    print \"conbined_data:\", conbined_data.shape\n",
    "\n",
    "    # Deal with categorical values\n",
    "    for c in conbined_data.columns:\n",
    "        if conbined_data[c].dtype == 'object':\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(conbined_data[c].values))\n",
    "            conbined_data[c] = lbl.transform(list(conbined_data[c].values))\n",
    "\n",
    "    train = conbined_data.iloc[:train.shape[0], :]\n",
    "    test = conbined_data.iloc[train.shape[0]:, :]\n",
    "\n",
    "    test_size = (1.0 * test.shape[0]) / train.shape[0]\n",
    "    print \"submit test size:\", test_size\n",
    "\n",
    "    # Convert to numpy values\n",
    "    X_all = train.values\n",
    "\n",
    "    # Create a validation set, with last 20% of data\n",
    "    num_train = int(train.shape[0] / (1+test_size))\n",
    "\n",
    "    X_train_all = X_all\n",
    "    X_test = test\n",
    "\n",
    "    # X_train = X_all[:num_train]\n",
    "    # X_val = X_all[num_train:]\n",
    "    # ylog_train = ylog_train_all[:num_train]\n",
    "    # ylog_val = ylog_train_all[num_train:]\n",
    "\n",
    "    X_train, X_val, ylog_train, ylog_val=train_test_split(X_all, ylog_train_all, test_size=test_size, \n",
    "                                                random_state=123)\n",
    "\n",
    "    print \"validate size:\", 1.0*X_val.shape[0] / X_train.shape[0]\n",
    "\n",
    "    df_columns = train.columns\n",
    "\n",
    "    print('X_train_all shape is', X_train_all.shape)\n",
    "    print('X_train shape is', X_train.shape)\n",
    "    print('y_train shape is', ylog_train.shape)\n",
    "    print('X_val shape is', X_val.shape)\n",
    "    print('y_val shape is', ylog_val.shape)\n",
    "    print('X_test shape is', X_test.shape)\n",
    "    \n",
    "    dtrain_all = xgb.DMatrix(X_train_all, ylog_train_all, feature_names=df_columns)\n",
    "    dtrain = xgb.DMatrix(X_train, ylog_train, feature_names=df_columns)\n",
    "    dval = xgb.DMatrix(X_val, ylog_val, feature_names=df_columns)\n",
    "    dtest = xgb.DMatrix(X_test, feature_names=df_columns)\n",
    "\n",
    "    xgb_params = {\n",
    "        'eta': 0.05,\n",
    "        'max_depth': 5,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'objective': 'reg:linear',\n",
    "        'eval_metric': 'rmse',\n",
    "        'silent': 1,\n",
    "        'seed':5\n",
    "    }\n",
    "\n",
    "    num_round = 1000\n",
    "    xgb_params['nthread'] = 24\n",
    "    evallist = [(dval, 'eval')]\n",
    "\n",
    "    bst = xgb.train(xgb_params, dtrain, num_round, evallist, early_stopping_rounds=40, verbose_eval=10)\n",
    "    \n",
    "    if (isLog1p):\n",
    "        train_rmse = mean_squared_error(ylog_train, bst.predict(dtrain))\n",
    "        val_rmse = mean_squared_error(ylog_val, bst.predict(dval))\n",
    "    else:\n",
    "        train_rmse = mean_squared_error(np.log1p(ylog_train), np.log1p(bst.predict(dtrain)))\n",
    "        val_rmse = mean_squared_error(np.log1p(ylog_val), np.log1p(bst.predict(dval)))\n",
    "    print 'train_rmse =', np.sqrt(train_rmse), ', val_rmse =', np.sqrt(val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conbined_data: (36650, 702)\n",
      "submit test size: 0.264316268801\n",
      "validate size: 0.359279752415\n",
      "('X_train_all shape is', (28988, 702))\n",
      "('X_train shape is', (21326, 702))\n",
      "('y_train shape is', (21326,))\n",
      "('X_val shape is', (7662, 702))\n",
      "('y_val shape is', (7662,))\n",
      "('X_test shape is', (7662, 702))\n",
      "[0]\teval-rmse:14.401\n",
      "Will train until eval-rmse hasn't improved in 40 rounds.\n",
      "[10]\teval-rmse:8.62748\n",
      "[20]\teval-rmse:5.17376\n",
      "[30]\teval-rmse:3.11093\n",
      "[40]\teval-rmse:1.88354\n",
      "[50]\teval-rmse:1.1597\n",
      "[60]\teval-rmse:0.744146\n",
      "[70]\teval-rmse:0.517844\n",
      "[80]\teval-rmse:0.406038\n",
      "[90]\teval-rmse:0.356851\n",
      "[100]\teval-rmse:0.336461\n",
      "[110]\teval-rmse:0.328658\n",
      "[120]\teval-rmse:0.325175\n",
      "[130]\teval-rmse:0.323587\n",
      "[140]\teval-rmse:0.322657\n",
      "[150]\teval-rmse:0.322152\n",
      "[160]\teval-rmse:0.321778\n",
      "[170]\teval-rmse:0.32146\n",
      "[180]\teval-rmse:0.321216\n",
      "[190]\teval-rmse:0.320811\n",
      "[200]\teval-rmse:0.320791\n",
      "[210]\teval-rmse:0.320634\n",
      "[220]\teval-rmse:0.320532\n",
      "[230]\teval-rmse:0.320243\n",
      "[240]\teval-rmse:0.320344\n",
      "[250]\teval-rmse:0.320179\n",
      "[260]\teval-rmse:0.320107\n",
      "[270]\teval-rmse:0.320093\n",
      "[280]\teval-rmse:0.320061\n",
      "[290]\teval-rmse:0.320252\n",
      "[300]\teval-rmse:0.320291\n",
      "[310]\teval-rmse:0.320471\n",
      "[320]\teval-rmse:0.320517\n",
      "Stopping. Best iteration:\n",
      "[281]\teval-rmse:0.319991\n",
      "\n",
      "train_rmse = 0.257648786803 , val_rmse = 0.320517933831\n"
     ]
    }
   ],
   "source": [
    "CV(True)\n",
    "#not log1p, original train_rmse = 0.252746403304 , val_rmse = 0.320226748185\n",
    "#log1p, orginal train_rmse = 0.257648786803 , val_rmse = 0.320517933831, \n",
    "\n",
    "#log1p, my deleted train_rmse = 0.257648786803 , val_rmse = 0.320517933831, \n",
    "#log1p, my deleted added train_rmse = 0.257648786803 , val_rmse = 0.320517933831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
